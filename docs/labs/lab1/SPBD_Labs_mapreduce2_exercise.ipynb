{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smduarte/spbd-2425/blob/main/docs/labs/lab1/SPBD_Labs_mapreduce2_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Count Exercises\n",
        "\n",
        "Count the number of occurrences of each word...\n",
        "\n",
        "a) No sorting required, words and frequency can appear in any order;\n",
        "\n",
        "b) Sorted by word, in increasing alphabetical order;\n",
        "\n",
        "c) Sorted by frequency (the words with higher occurrence first)."
      ],
      "metadata": {
        "id": "6CsK5ie3Osec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the input file\n",
        "!wget -q -O os_maias.txt https://www.dropbox.com/s/n24v0z7y79np319/os_maias.txt?dl=0"
      ],
      "metadata": {
        "id": "z7TVcw3oQFcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def simple_word_count(file_path):\n",
        "    word_counts = {}\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Remove punctuation and convert to lowercase\n",
        "            line = line.translate(str.maketrans('', '', string.punctuation+'«»')).lower()\n",
        "            words = line.split()\n",
        "            for word in words:\n",
        "                word_counts[word] = word_counts.get(word, 0) + 1\n",
        "    return word_counts\n",
        "\n",
        "# Specify the path to the downloaded file\n",
        "file_path = 'os_maias.txt'\n",
        "word_counts = simple_word_count(file_path)\n",
        "\n",
        "# Print the word counts\n",
        "for word, count in word_counts.items():\n",
        "    print(f'{word}: {count}')"
      ],
      "metadata": {
        "id": "R0qtbq6zPA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtsPM1Z4HH7M"
      },
      "source": [
        "# Python MapReduce Exercises\n",
        "\n",
        "##1. MrJob MapReduce Word Frequency\n",
        "\n",
        "Using the [MrJob](https://mrjob.readthedocs.io/en/latest/) library, create a map-reduce program that counts the number of occurrences of each word.\n",
        "\n",
        "**a)** No sorting required, words and frequency can appear in any order;\n",
        "\n",
        "**b)** Sorted by word, in increasing alphabetical order;\n",
        "\n",
        "**c)** Sorted by frequency (the words with higher occurrence first).\n",
        "\n",
        "**IMPORTANT**: Check the MrJob documentation to see how multi-step MapReduce jobs can\n",
        "be implemented in the same Python class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the Dataset and Install MrJob\n",
        "!wget -q -O os_maias.txt https://www.dropbox.com/s/n24v0z7y79np319/os_maias.txt?dl=0\n",
        "! pip install mrjob --quiet\n",
        "!wget -q -O /etc/mrjob.conf https://raw.githubusercontent.com/smduarte/spbd-2526/main/docs/labs/lab1/mrjob.conf"
      ],
      "metadata": {
        "id": "ZB6X55GwaK0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Exercise 1a)\n",
        "%%file word_freq_1a.py\n",
        "\n",
        "import string\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRWordCountFrequency1a(MRJob):\n",
        "\n",
        "  def mapper(self, _, line):\n",
        "    None\n",
        "\n",
        "  def reducer(self, key, values):\n",
        "    None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRWordCountFrequency1a.run()"
      ],
      "metadata": {
        "id": "0xXW5IFNZdNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf results\n",
        "!python3 -m word_freq_1a -r local --output-dir results --cleanup NONE os_maias.txt\n",
        "!cat results/*"
      ],
      "metadata": {
        "id": "9tkKbIOvZhnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Exercise 1b)\n",
        "%%file word_freq_1b.py\n",
        "\n",
        "import string\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRWordCountFrequency1b(MRJob):\n",
        "\n",
        "  def mapper(self, _, line):\n",
        "    None\n",
        "\n",
        "  def reducer(self, key, values):\n",
        "    None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRWordCountFrequency1b.run()\n"
      ],
      "metadata": {
        "id": "hTpnAjifa9tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf results\n",
        "!python3 -m word_freq_1b -r local --output-dir results --cleanup NONE os_maias.txt\n",
        "!cat results/*"
      ],
      "metadata": {
        "id": "35e6ItsNkC7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Exercise 1c)\n",
        "%%file word_freq_1c.py\n",
        "\n",
        "import string\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRWordCountFrequency1c(MRJob):\n",
        "\n",
        "  def mapper(self, _, line):\n",
        "    None\n",
        "\n",
        "  def reducer(self, key, values):\n",
        "    None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRWordCountFrequency1c.run()\n"
      ],
      "metadata": {
        "id": "QPT00N0da93K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf results\n",
        "!python3 -m word_freq_1c -r local --output-dir results --cleanup NONE os_maias.txt\n",
        "!cat results/*"
      ],
      "metadata": {
        "id": "IWXj1GOakEup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Weblog Analysis\n",
        "\n",
        "Consider a set of log files captured during a DDOS (*Distributed Denial of Service*) attack, containing information for the web accesses performed during the attack to the server.\n",
        "\n",
        "Create a new notebook that processes the log of web entries using MrJob and map-reduce to:\n",
        "\n",
        "1. Count the number of unique IP addresses involved in the DDOS attack.\n",
        "\n",
        "2. For each interval of 10 seconds, provide the following information: [number of requests, average execution time, maximum time, minimum time]\n",
        "\n",
        "3. Create an inverted index that, for each interval of 10 seconds, has a list of (unique) IPs executing accesses (to each URL).\n",
        "\n",
        "\n",
        "The log files contain text lines as shown below, with TAB as the separator:\n",
        "\n",
        "date |IP_source | status_code | operation | URL | execution time |\n",
        "-|-|-|-|-|-\n",
        "timestamp  | string | int | string | string| float |\n",
        "2016-12-06T08:58:35.318+0000|37.139.9.11|404|GET|/codemove/TTCENCUFMH3C|0.026\n",
        "\n",
        "<br>\n",
        "The log can be downloaded from:\n",
        "\n",
        "[https://www.dropbox.com/s/0r8902uj9yum7dg/web.log?dl=0](https://www.dropbox.com/s/0r8902uj9yum7dg/web.log?dl=0)\n",
        "\n",
        "Suggestion: to start, make a copy an existing notebook and modify it.\n",
        "\n",
        "If you really must..., you can use [dateutil.parser](https://dateutil.readthedocs.io/en/stable/parser.html) for decoding timestamps."
      ],
      "metadata": {
        "id": "rsJZWYlHZDJL"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}