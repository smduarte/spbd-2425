{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smduarte/spbd-2324/blob/main/lab3/SPBD_Labs_mapreduce2_exercise_solution2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKGXsDUIDxH6"
      },
      "source": [
        "# MrJob MapReduce Python Example\n",
        "\n",
        "Word count implemented in pure Python, using the library MrJob.\n",
        "\n",
        "[MrJob](https://mrjob.readthedocs.io/en/latest/) can be used to write MapReduce jobs and run them on several platforms.\n",
        "\n",
        "Some key advantages:\n",
        "+ Write **multi-step** MapReduce jobs in pure Python;\n",
        "+ Test on your **local machine**;\n",
        "+ Deploy jobs in several cloud plataforms of several vendors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "B68ZyGdPDxH9"
      },
      "outputs": [],
      "source": [
        "#@title Download the dataset and install MrJob\n",
        "!wget -q -O os_maias.txt https://www.dropbox.com/s/n24v0z7y79np319/os_maias.txt?dl=0\n",
        "!pip install mrjob --quiet\n",
        "!wget -q -O /etc/mrjob.conf https://raw.githubusercontent.com/smduarte/spbd-2324/main/lab2/mrjob.conf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8sllMoIDxH_"
      },
      "source": [
        "##1. MrJob MapReduce Word Frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbItx5zwDxIA"
      },
      "outputs": [],
      "source": [
        "%%file desc_word_freq.py\n",
        "\n",
        "import string\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "MAX_FREQ=100000\n",
        "\n",
        "class MRWordCountFrequency(MRJob):\n",
        "\n",
        "    def mapper_words(self, _, line):\n",
        "      line = line.strip()\n",
        "      line = line.translate(str.maketrans('', '', string.punctuation+'«»'))\n",
        "      for word in line.split():\n",
        "        yield word, 1\n",
        "\n",
        "    def reducer_words(self, key, values):\n",
        "        yield key, sum(values)\n",
        "\n",
        "    def mapper_partition_sort(self, word, freq):\n",
        "      yield '%05d' % (MAX_FREQ-freq), word\n",
        "\n",
        "    def reducer_partition_sort(self, freq, words):\n",
        "      for word in words:\n",
        "        yield word, MAX_FREQ-int(freq)\n",
        "\n",
        "    def mapper_total_sort(self, word, freq):\n",
        "      yield None, (word, freq)\n",
        "\n",
        "    def reducer_total_sort(self, _, values):\n",
        "      for word, freq in sorted(values, key= lambda x: x[1], reverse=True):\n",
        "        yield word, freq\n",
        "\n",
        "    def steps(self):\n",
        "        return [ MRStep(mapper=self.mapper_words, reducer=self.reducer_words),\n",
        "                 MRStep(mapper=self.mapper_partition_sort, reducer=self.reducer_partition_sort),\n",
        "                 MRStep(mapper=self.mapper_total_sort, reducer=self.reducer_total_sort)]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRWordCountFrequency.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf results\n",
        "!python -m desc_word_freq  --output-dir results --cleanup NONE os_maias.txt\n",
        "!head results/*"
      ],
      "metadata": {
        "id": "pHfn6fXDMlhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Weblog DDOS Attack Analysis"
      ],
      "metadata": {
        "id": "nEKwrA3bcaqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O web.log https://www.dropbox.com/s/0r8902uj9yum7dg/web.log?dl=0\n",
        "!wc web.log"
      ],
      "metadata": {
        "id": "1-grZ0LCJkpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Count the number of unique IP addresses involved in the DDOS attack.\n",
        "\n"
      ],
      "metadata": {
        "id": "KVACuyCdgJIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file unique_ips.py\n",
        "\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRUniqueIPs(MRJob):\n",
        "\n",
        "    def steps(self):\n",
        "      return [MRStep(mapper=self.mapper_ip, reducer=self.reducer_ip),\n",
        "              MRStep(reducer=self.reducer_filter)]\n",
        "\n",
        "    def mapper_ip(self, _, line):\n",
        "      _, ip_source, _ = line.strip().split(' ', 2)\n",
        "      yield ip_source, None\n",
        "\n",
        "    def reducer_ip(self, ip_source, _):\n",
        "      yield None, 1\n",
        "\n",
        "    def reducer_filter(self, _, values):\n",
        "      yield \"UNIQUE IPs\", sum(values)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRUniqueIPs.run()"
      ],
      "metadata": {
        "id": "b1d12MZlTHy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf results\n",
        "!python -m unique_ips  --output-dir results --cleanup NONE web.log\n",
        "!head results/*"
      ],
      "metadata": {
        "id": "uDFifGR8c9dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. For each interval of 10 seconds, provide the following information: [number of requests, average execution time, maximum time, minimum time]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EGXyirG3gPUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file interval_stats.py\n",
        "\n",
        "from statistics import *\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRIntervalStats(MRJob):\n",
        "\n",
        "  def mapper(self, _, line):\n",
        "        vals = line.strip().split(' ')\n",
        "        timestamp = vals[0]\n",
        "        execution_time = float(vals[5])\n",
        "        interval = timestamp[0:18] # YYYY-MM-DDTHH:MM:S -> 10s intervals\n",
        "        yield interval, execution_time\n",
        "\n",
        "  def reducer(self, interval, values):\n",
        "      times = list(values)\n",
        "      yield interval, (len(times), min(times), mean(times), max(times))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRIntervalStats.run()"
      ],
      "metadata": {
        "id": "IHTJrPA0Vtlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "rm -rf results\n",
        "python -m interval_stats --output-dir results --cleanup NONE web.log && head results/*"
      ],
      "metadata": {
        "id": "NBNMqPDAl6c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file interval_stats2.py\n",
        "\n",
        "from statistics import *\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRIntervalStats2(MRJob):\n",
        "\n",
        "  def mapper(self, _, line):\n",
        "        vals = line.strip().split(' ')\n",
        "        timestamp = vals[0]\n",
        "        execution_time = float(vals[5])\n",
        "        interval = timestamp[0:18] # YYYY-MM-DDTHH:MM:S -> 10s intervals\n",
        "        yield interval, (execution_time, execution_time, execution_time, 1)\n",
        "\n",
        "  def combiner(self, interval, values):\n",
        "        tuples = list(values)\n",
        "        sum_exec_time = sum( [i[0] for i in tuples] )\n",
        "        min_exec_time = min( [i[1] for i in tuples] )\n",
        "        max_exec_time = max( [i[2] for i in tuples] )\n",
        "        tot_exec_time = sum( [i[3] for i in tuples] )\n",
        "        yield interval, (sum_exec_time, min_exec_time, max_exec_time, tot_exec_time)\n",
        "\n",
        "  def reducer(self, interval, values):\n",
        "        tuples = list(values)\n",
        "        sum_exec_time = sum( [i[0] for i in tuples] )\n",
        "        min_exec_time = min( [i[1] for i in tuples] )\n",
        "        max_exec_time = max( [i[2] for i in tuples] )\n",
        "        tot_exec_time = sum( [i[3] for i in tuples] )\n",
        "        yield interval, (tot_exec_time, min_exec_time, sum_exec_time/tot_exec_time, max_exec_time)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRIntervalStats2.run()"
      ],
      "metadata": {
        "id": "Q0RWMLk3s2fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "rm -rf results\n",
        "python -m interval_stats2 --output-dir results --cleanup NONE web.log && head results/*"
      ],
      "metadata": {
        "id": "gEftivd3vTAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file interval_stats2.py\n",
        "\n",
        "from statistics import *\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRIntervalStats2(MRJob):\n",
        "\n",
        "  def mapper(self, _, line):\n",
        "        vals = line.strip().split(' ')\n",
        "        timestamp = vals[0]\n",
        "        execution_time = float(vals[5])\n",
        "        interval = timestamp[0:18] # YYYY-MM-DDTHH:MM:S -> 10s intervals\n",
        "        yield interval, (execution_time, execution_time, execution_time, 1)\n",
        "\n",
        "  def combiner(self, interval, values):\n",
        "        sum_exec_time = sum( [i[0] for i in values] )\n",
        "        min_exec_time = min( [i[1] for i in values] )\n",
        "        max_exec_time = max( [i[2] for i in values] )\n",
        "        tot_exec_time = sum( [i[3] for i in values] )\n",
        "        yield interval, (sum_exec_time, min_exec_time, max_exec_time, tot_exec_time)\n",
        "\n",
        "  def reducer(self, interval, values):\n",
        "        sum_exec_time = sum( [i[0] for i in values] )\n",
        "        min_exec_time = min( [i[1] for i in values] )\n",
        "        max_exec_time = max( [i[2] for i in values] )\n",
        "        tot_exec_time = sum( [i[3] for i in values] )\n",
        "        yield interval, (tot_exec_time, min_exec_time, sum_exec_time/tot_exec_time, max_exec_time)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRIntervalStats2.run()"
      ],
      "metadata": {
        "id": "spC2AiAMv2_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create an inverted index that, for each interval of 10 seconds, has a list of (unique) IPs executing accesses (to each URL)."
      ],
      "metadata": {
        "id": "Lz8Tua3EkFY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file inverted_index.py\n",
        "\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRInvertedIndex(MRJob):\n",
        "\n",
        "  def mapper(self, _, line):\n",
        "        vals = line.strip().split(' ')\n",
        "        if len(vals) >= 6:\n",
        "          timestamp = vals[0]\n",
        "          interval = timestamp[0:18] # YYYY-MM-DDTHH:MM:S -> 10s intervals\n",
        "\n",
        "          source_ip = vals[1]\n",
        "          target_url = vals[4]\n",
        "          yield \"{}-{}\".format(interval, target_url), source_ip\n",
        "\n",
        "  def reducer(self, key, values):\n",
        "    yield key, list(values)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRInvertedIndex.run()"
      ],
      "metadata": {
        "id": "SohWRLLVkKYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "rm -rf results\n",
        "python -m inverted_index --output-dir results web.log && head results/*"
      ],
      "metadata": {
        "id": "drW4DsP2mCem"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}